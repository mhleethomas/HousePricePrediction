{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08905150",
   "metadata": {
    "papermill": {
     "duration": 0.024971,
     "end_time": "2024-10-28T22:58:03.224091",
     "exception": false,
     "start_time": "2024-10-28T22:58:03.199120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Table of Contents\n",
    "1. Data Import\n",
    "2. Data Structure & Summary Static of the Data\n",
    "3. Data Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Feature Selection and Model Selection\n",
    "6. Best Model and Best Features\n",
    "7. Results, Findings, and Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b9776",
   "metadata": {
    "papermill": {
     "duration": 0.022221,
     "end_time": "2024-10-28T22:58:03.269276",
     "exception": false,
     "start_time": "2024-10-28T22:58:03.247055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59166646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:58:03.316938Z",
     "iopub.status.busy": "2024-10-28T22:58:03.316536Z",
     "iopub.status.idle": "2024-10-28T22:58:06.185245Z",
     "shell.execute_reply": "2024-10-28T22:58:06.184386Z"
    },
    "papermill": {
     "duration": 2.896031,
     "end_time": "2024-10-28T22:58:06.187763",
     "exception": false,
     "start_time": "2024-10-28T22:58:03.291732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "#In order to draw in jupyter you need to use this command\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "corlor = sns.color_palette()\n",
    "sns.set_style('darkgrid') #Set the drawing background\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "#Statistical: normal distribution, skewness\n",
    "\n",
    "\n",
    "#Limited to three decimal places\n",
    "pd.set_option('display.float_format', lambda x:'{:.3f}'.format(x))\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "412aafa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:58:06.235233Z",
     "iopub.status.busy": "2024-10-28T22:58:06.234621Z",
     "iopub.status.idle": "2024-10-28T22:58:06.363537Z",
     "shell.execute_reply": "2024-10-28T22:58:06.362611Z"
    },
    "papermill": {
     "duration": 0.15546,
     "end_time": "2024-10-28T22:58:06.366095",
     "exception": false,
     "start_time": "2024-10-28T22:58:06.210635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3a534b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:58:06.413586Z",
     "iopub.status.busy": "2024-10-28T22:58:06.412697Z",
     "iopub.status.idle": "2024-10-28T22:58:08.138512Z",
     "shell.execute_reply": "2024-10-28T22:58:08.137565Z"
    },
    "papermill": {
     "duration": 1.752091,
     "end_time": "2024-10-28T22:58:08.141041",
     "exception": false,
     "start_time": "2024-10-28T22:58:06.388950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2fbda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:58:08.188495Z",
     "iopub.status.busy": "2024-10-28T22:58:08.187433Z",
     "iopub.status.idle": "2024-10-28T22:58:08.407736Z",
     "shell.execute_reply": "2024-10-28T22:58:08.406394Z"
    },
    "papermill": {
     "duration": 0.246448,
     "end_time": "2024-10-28T22:58:08.410166",
     "exception": false,
     "start_time": "2024-10-28T22:58:08.163718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#XGBoost need\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698aaf35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:58:08.460151Z",
     "iopub.status.busy": "2024-10-28T22:58:08.459745Z",
     "iopub.status.idle": "2024-10-28T22:58:09.358313Z",
     "shell.execute_reply": "2024-10-28T22:58:09.356871Z"
    },
    "papermill": {
     "duration": 0.92448,
     "end_time": "2024-10-28T22:58:09.360029",
     "exception": true,
     "start_time": "2024-10-28T22:58:08.435549",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/train-df/training_dataset-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import and put the data into pandas\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/train-df/training_dataset-1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/test-df/test_dataset-1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/train-df/training_dataset-1.csv'"
     ]
    }
   ],
   "source": [
    "#Import and put the data into pandas\n",
    "train_df = pd.read_csv('/kaggle/input/train-df/training_dataset-1.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/test-df/test_dataset-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51cb8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Data Structure & A summary statistic of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8b2cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.558259Z",
     "iopub.status.busy": "2024-10-28T22:51:27.557815Z",
     "iopub.status.idle": "2024-10-28T22:51:27.576443Z",
     "shell.execute_reply": "2024-10-28T22:51:27.575436Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.558206Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the data structure, check if there are missing values, and check the data type\n",
    "print(\"\\nTraining Data Info:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0583afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.577980Z",
     "iopub.status.busy": "2024-10-28T22:51:27.577650Z",
     "iopub.status.idle": "2024-10-28T22:51:27.600754Z",
     "shell.execute_reply": "2024-10-28T22:51:27.599485Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.577944Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#View the first 5 rows of data in the training set\n",
    "print(\"Traning data:\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bdaf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.602940Z",
     "iopub.status.busy": "2024-10-28T22:51:27.602550Z",
     "iopub.status.idle": "2024-10-28T22:51:27.619990Z",
     "shell.execute_reply": "2024-10-28T22:51:27.618560Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.602899Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Classify features according to data type to facilitate subsequent processing\n",
    "train_df.groupby(train_df.dtypes,axis=1).apply(lambda x:x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3507c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "·id - Unique ID for each home sold \n",
    "·date - Date of the home sale \n",
    "·price - Price of each home sold \n",
    "·bedrooms - Number of bedrooms \n",
    "·bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower \n",
    "·sqft_living - Square footage of the apartments interior living space \n",
    "·sqft_lot - Square footage of the land space \n",
    "·floors - Number of floors \n",
    "·waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not \n",
    "·view - An index from 0 to 4 of how good the view of the property was \n",
    "·condition - An index from 1 to 5 on the condition of the apartment, \n",
    "·grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design. \n",
    "·sqft_above - The square footage of the interior housing space that is above ground level \n",
    "·sqft_basement - The square footage of the interior housing space that is below ground level \n",
    "·yr_built - The year the house was initially built \n",
    "·yr_renovated - The year of the house’s last renovation \n",
    "·zipcode - What zipcode area the house is in \n",
    "·lat - Lattitude \n",
    "·long - Longitude \n",
    "·sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors \n",
    "·sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b1a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.621501Z",
     "iopub.status.busy": "2024-10-28T22:51:27.621138Z",
     "iopub.status.idle": "2024-10-28T22:51:27.627749Z",
     "shell.execute_reply": "2024-10-28T22:51:27.626600Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.621462Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the data size before deleting the id\n",
    "print(\"\\nThe train data size before dropping id feature is: {}\".format(train_df.shape))\n",
    "print(\"\\nThe test data size before dropping id feature is: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344d328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.634098Z",
     "iopub.status.busy": "2024-10-28T22:51:27.633582Z",
     "iopub.status.idle": "2024-10-28T22:51:27.704860Z",
     "shell.execute_reply": "2024-10-28T22:51:27.703765Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.634043Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting Numeric Features\n",
    "numeric_features = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate descriptive statistics and transpose\n",
    "numeric_stats = numeric_features.describe().T  \n",
    "# Transpose the descriptive statistics and store them in numeric_stats\n",
    "\n",
    "# Add median\n",
    "numeric_stats['median'] = numeric_features.median()  \n",
    "\n",
    "# Print statistics of numeric features\n",
    "print(\"Statistics of numerical features:\")\n",
    "print(numeric_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29682fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:27.706797Z",
     "iopub.status.busy": "2024-10-28T22:51:27.706427Z",
     "iopub.status.idle": "2024-10-28T22:51:28.328745Z",
     "shell.execute_reply": "2024-10-28T22:51:28.327469Z",
     "shell.execute_reply.started": "2024-10-28T22:51:27.706757Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Histogram: Displays the distribution of housing prices\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(train_df['price'], bins=30, kde=True)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8408a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:28.331001Z",
     "iopub.status.busy": "2024-10-28T22:51:28.330529Z",
     "iopub.status.idle": "2024-10-28T22:51:28.987802Z",
     "shell.execute_reply": "2024-10-28T22:51:28.986686Z",
     "shell.execute_reply.started": "2024-10-28T22:51:28.330946Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the style of the graph\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y=train_df['price'])  \n",
    "# draw a box plot of price using the y-axis\n",
    "plt.title('Boxplot of House Prices')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('House Price')\n",
    "plt.grid(axis='y')  \n",
    "# Add y-axis grid lines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe2d19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d7a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    " ### Create Price Heatmap using Location Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85947b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:28.989465Z",
     "iopub.status.busy": "2024-10-28T22:51:28.989095Z",
     "iopub.status.idle": "2024-10-28T22:51:30.643975Z",
     "shell.execute_reply": "2024-10-28T22:51:30.642631Z",
     "shell.execute_reply.started": "2024-10-28T22:51:28.989425Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Price Heatmap using Latitudes and Longitudes\n",
    "# import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Load your dataset\n",
    "data = train_df\n",
    "\n",
    "# Filter out rows where price or lat/long might be missing\n",
    "data = data.dropna(subset=['lat', 'long', 'price'])\n",
    "\n",
    "# Initialize a map centered around the average location\n",
    "map_center = [data['lat'].mean(), data['long'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles=\"OpenStreetMap\")\n",
    "\n",
    "# Prepare data for the heatmap: [latitude, longitude, weight (price)]\n",
    "heat_data = [[row['lat'], row['long'], row['price']] for index, row in data.iterrows()]\n",
    "\n",
    "# Create a heatmap layer without max_val\n",
    "HeatMap(heat_data, min_opacity=0.2, max_zoom=15, radius=10, blur=15).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m.save(\"price_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01654a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:30.646322Z",
     "iopub.status.busy": "2024-10-28T22:51:30.645942Z",
     "iopub.status.idle": "2024-10-28T22:51:34.914667Z",
     "shell.execute_reply": "2024-10-28T22:51:34.913442Z",
     "shell.execute_reply.started": "2024-10-28T22:51:30.646254Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a heatmap of zipcode & housing prices per square meter\n",
    "\n",
    "# Create a new DataFrame to avoid affecting the original data\n",
    "temp_df = train_df.copy()\n",
    "\n",
    "# Calculate the price to living area ratio for each zipcode\n",
    "temp_df['price_per_sqft'] = temp_df['price'] / temp_df['sqft_living']\n",
    "avg_price_per_zipcode = temp_df.groupby('zipcode')['price_per_sqft'].mean().reset_index()\n",
    "\n",
    "# Convert the zipcode column to string type to match gdf_zipcodes\n",
    "avg_price_per_zipcode['zipcode'] = avg_price_per_zipcode['zipcode'].astype(str)\n",
    "\n",
    "# Read the zipcode's geographic boundary data\n",
    "zipcode_shapefile = '/kaggle/input/zipcode/Zipcodes.geojson' \n",
    "# Replace with everyone's own file path\n",
    "gdf_zipcodes = gpd.read_file(zipcode_shapefile)\n",
    "\n",
    "# Merge geographic data with average price to living area ratio data\n",
    "gdf_merged = gdf_zipcodes.merge(avg_price_per_zipcode, left_on='ZIPCODE', right_on='zipcode', how='left')\n",
    "\n",
    "# Set the color of the heat map\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "gdf_merged.boundary.plot(ax=ax, linewidth=1, color='black')  \n",
    "# Draw the border\n",
    "gdf_merged.plot(column='price_per_sqft', ax=ax, legend=True,\n",
    "                legend_kwds={'label': \"Average Price per Sqft by Zipcode\",\n",
    "                             'orientation': \"horizontal\"},\n",
    "                cmap='coolwarm', missing_kwds={\"color\": \"lightgrey\"})  \n",
    "# Missing values are set to gray\n",
    "\n",
    "# Set the latitude and longitude range\n",
    "ax.set_xlim(-122.50, -121.25)  \n",
    "# Longitude range\n",
    "ax.set_ylim(47.1, 47.8)        \n",
    "# Latitude range\n",
    "\n",
    "plt.title('Average Price per Square Foot by Zipcode')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aec93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T02:27:21.629931Z",
     "iopub.status.busy": "2024-10-25T02:27:21.629059Z",
     "iopub.status.idle": "2024-10-25T02:27:21.637127Z",
     "shell.execute_reply": "2024-10-25T02:27:21.635794Z",
     "shell.execute_reply.started": "2024-10-25T02:27:21.629882Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61eccda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:34.917451Z",
     "iopub.status.busy": "2024-10-28T22:51:34.916947Z",
     "iopub.status.idle": "2024-10-28T22:51:34.924474Z",
     "shell.execute_reply": "2024-10-28T22:51:34.923138Z",
     "shell.execute_reply.started": "2024-10-28T22:51:34.917396Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data processing on outliers and null values\n",
    "#For numeric variables, use y to do a scatterplot of house prices, find outliers and delete abnormal data\n",
    "def plot_data_scatterplot_for_train_df(x):\n",
    "    \n",
    "   plt.figure(figsize=(8, 6))\n",
    "   sns.scatterplot(x=x, y='price', data=train_df)\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3a9ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:34.926447Z",
     "iopub.status.busy": "2024-10-28T22:51:34.925964Z",
     "iopub.status.idle": "2024-10-28T22:51:34.940983Z",
     "shell.execute_reply": "2024-10-28T22:51:34.939787Z",
     "shell.execute_reply.started": "2024-10-28T22:51:34.926390Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.columns[train_df.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43275a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efab00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:34.942890Z",
     "iopub.status.busy": "2024-10-28T22:51:34.942505Z",
     "iopub.status.idle": "2024-10-28T22:51:43.216446Z",
     "shell.execute_reply": "2024-10-28T22:51:43.215350Z",
     "shell.execute_reply.started": "2024-10-28T22:51:34.942851Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columns don't have outliers\n",
    "def plot_data_scatterplot_with_boxplot(column):\n",
    "    # Create a two-column chart layout\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), gridspec_kw={'width_ratios': [3, 1]})\n",
    "    \n",
    "    # Draw a scatter plot on the left\n",
    "    sns.scatterplot(data=train_df, x=column, y='price', ax=axes[0])\n",
    "    axes[0].set_title(f'Scatter Plot of {column} vs price')\n",
    "    \n",
    "    # Draw a box plot on the right\n",
    "    sns.boxplot(data=train_df, y=column, ax=axes[1])\n",
    "    axes[1].set_title(f'Box Plot of {column}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use the new function to draw scatter plots and box plots of columns\n",
    "columns_to_plot = ['floors', 'long', 'waterfront', 'view', 'condition', 'grade', \n",
    "                   'yr_built', 'yr_renovated', 'zipcode', 'lat']\n",
    "for column in columns_to_plot:\n",
    "    plot_data_scatterplot_with_boxplot(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c780ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:43.218811Z",
     "iopub.status.busy": "2024-10-28T22:51:43.218267Z",
     "iopub.status.idle": "2024-10-28T22:51:49.937188Z",
     "shell.execute_reply": "2024-10-28T22:51:49.936006Z",
     "shell.execute_reply.started": "2024-10-28T22:51:43.218725Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Columns have outliers\n",
    "def plot_data_scatterplot_with_boxplot(column):\n",
    "    # Create a two-column chart layout\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), gridspec_kw={'width_ratios': [3, 1]})\n",
    "    \n",
    "    # Draw a scatter plot on the left\n",
    "    sns.scatterplot(data=train_df, x=column, y='price', ax=axes[0])\n",
    "    axes[0].set_title(f'Scatter Plot of {column} vs price')\n",
    "    \n",
    "    # Draw a box plot on the right\n",
    "    sns.boxplot(data=train_df, y=column, ax=axes[1])\n",
    "    axes[1].set_title(f'Box Plot of {column}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use the new function to draw scatter plots and box plots of columns\n",
    "columns_to_plot = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', \n",
    "                   'sqft_living15', 'sqft_lot15']\n",
    "for column in columns_to_plot:\n",
    "    plot_data_scatterplot_with_boxplot(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001246d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:49.939322Z",
     "iopub.status.busy": "2024-10-28T22:51:49.938952Z",
     "iopub.status.idle": "2024-10-28T22:51:49.965637Z",
     "shell.execute_reply": "2024-10-28T22:51:49.964373Z",
     "shell.execute_reply.started": "2024-10-28T22:51:49.939256Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('bedrooms> 15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d85065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:49.967499Z",
     "iopub.status.busy": "2024-10-28T22:51:49.967011Z",
     "iopub.status.idle": "2024-10-28T22:51:49.997386Z",
     "shell.execute_reply": "2024-10-28T22:51:49.996254Z",
     "shell.execute_reply.started": "2024-10-28T22:51:49.967456Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('bathrooms> 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fcc632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:49.999938Z",
     "iopub.status.busy": "2024-10-28T22:51:49.999481Z",
     "iopub.status.idle": "2024-10-28T22:51:50.028486Z",
     "shell.execute_reply": "2024-10-28T22:51:50.027209Z",
     "shell.execute_reply.started": "2024-10-28T22:51:49.999885Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_living> 12000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4737ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.030576Z",
     "iopub.status.busy": "2024-10-28T22:51:50.030101Z",
     "iopub.status.idle": "2024-10-28T22:51:50.059040Z",
     "shell.execute_reply": "2024-10-28T22:51:50.057900Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.030521Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_lot> 1500000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80543639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.061080Z",
     "iopub.status.busy": "2024-10-28T22:51:50.060640Z",
     "iopub.status.idle": "2024-10-28T22:51:50.089193Z",
     "shell.execute_reply": "2024-10-28T22:51:50.087779Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.061038Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_above> 8000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580616fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.091570Z",
     "iopub.status.busy": "2024-10-28T22:51:50.091060Z",
     "iopub.status.idle": "2024-10-28T22:51:50.120963Z",
     "shell.execute_reply": "2024-10-28T22:51:50.119685Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.091517Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_basement> 3000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73206b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.122968Z",
     "iopub.status.busy": "2024-10-28T22:51:50.122609Z",
     "iopub.status.idle": "2024-10-28T22:51:50.149708Z",
     "shell.execute_reply": "2024-10-28T22:51:50.148520Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.122931Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_living15 > 6000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11a7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.151852Z",
     "iopub.status.busy": "2024-10-28T22:51:50.151492Z",
     "iopub.status.idle": "2024-10-28T22:51:50.178773Z",
     "shell.execute_reply": "2024-10-28T22:51:50.177440Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.151814Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.query('sqft_lot15 > 500000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16754a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.181469Z",
     "iopub.status.busy": "2024-10-28T22:51:50.180316Z",
     "iopub.status.idle": "2024-10-28T22:51:50.193265Z",
     "shell.execute_reply": "2024-10-28T22:51:50.192183Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.181405Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Delete house records with outlier IDs\n",
    "values = [2402100895, 1225069038, 6762700020, 9208900037, 424049043, 1020069017, 7767000060, 1924059029, 2524069078, 225079036, 3420069060 ]\n",
    "train_df = train_df[train_df.id.isin(values) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff47ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.203426Z",
     "iopub.status.busy": "2024-10-28T22:51:50.203026Z",
     "iopub.status.idle": "2024-10-28T22:51:50.209351Z",
     "shell.execute_reply": "2024-10-28T22:51:50.208228Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.203386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"After deletion: {}\".format(train_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c07a8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.212057Z",
     "iopub.status.busy": "2024-10-28T22:51:50.211609Z",
     "iopub.status.idle": "2024-10-28T22:51:50.221775Z",
     "shell.execute_reply": "2024-10-28T22:51:50.220500Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.212004Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "#Check whether the dependent variable price has missing values\n",
    "print(train_df['price'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e61ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.223622Z",
     "iopub.status.busy": "2024-10-28T22:51:50.223187Z",
     "iopub.status.idle": "2024-10-28T22:51:50.239852Z",
     "shell.execute_reply": "2024-10-28T22:51:50.238580Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.223583Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Concat test and train data\n",
    "# Reset the index before merging\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "all_data = pd.concat([train_df, test_df])\n",
    "all_data.tail(10)\n",
    "print(\"After combine all data: {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d7202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.241781Z",
     "iopub.status.busy": "2024-10-28T22:51:50.241407Z",
     "iopub.status.idle": "2024-10-28T22:51:50.261795Z",
     "shell.execute_reply": "2024-10-28T22:51:50.260450Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.241740Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Directly check whether there are missing values ​​in the data set, but do not display the price column\n",
    "missing_values = all_data.filter(regex='^(?!price$)').isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33e2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.264537Z",
     "iopub.status.busy": "2024-10-28T22:51:50.263860Z",
     "iopub.status.idle": "2024-10-28T22:51:50.273880Z",
     "shell.execute_reply": "2024-10-28T22:51:50.272846Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.264480Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handling missing values in yr_renovated\n",
    "all_data['yr_renovated'] = np.where(all_data['yr_renovated'] == 0, all_data['yr_built'], all_data['yr_renovated'])\n",
    "\n",
    "# Check whether the replacement is successful\n",
    "print(\"Unique values ​​of the 'yr_renovated' column in the processed training set:\")\n",
    "print(all_data['yr_renovated'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.275860Z",
     "iopub.status.busy": "2024-10-28T22:51:50.275476Z",
     "iopub.status.idle": "2024-10-28T22:51:50.290817Z",
     "shell.execute_reply": "2024-10-28T22:51:50.289545Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.275810Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Re-split all_data into train_df and test_df based on updated size of train_df\n",
    "train_df = all_data.iloc[:len(train_df), :].copy()\n",
    "test_df = all_data.iloc[len(train_df):, :].copy()\n",
    "\n",
    "#check date shape\n",
    "print(\"\\nThe train data size is: {}\".format(train_df.shape))\n",
    "print(\"\\nThe test data size is: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411c886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.292621Z",
     "iopub.status.busy": "2024-10-28T22:51:50.292239Z",
     "iopub.status.idle": "2024-10-28T22:51:50.317339Z",
     "shell.execute_reply": "2024-10-28T22:51:50.316010Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.292580Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Handling missing values in bedrooms\n",
    "# show datas with bedrooms is 0\n",
    "bedrooms_zero_train = train_df[train_df['bedrooms'] == 0]\n",
    "bedrooms_zero_test = test_df[test_df['bedrooms'] == 0]\n",
    "print(\"Bedrooms = 0:\")\n",
    "print(bedrooms_zero_train)\n",
    "print(bedrooms_zero_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77fe0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.319375Z",
     "iopub.status.busy": "2024-10-28T22:51:50.318948Z",
     "iopub.status.idle": "2024-10-28T22:51:50.334402Z",
     "shell.execute_reply": "2024-10-28T22:51:50.333132Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.319327Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete rows with bedrooms ==0\n",
    "train_df = train_df[train_df['bedrooms'] != 0]\n",
    "test_df = test_df[test_df['bedrooms'] != 0]\n",
    "\n",
    "#Check the data size after data cleaning for bedrooms == 0\n",
    "print(\"\\nThe train data size after data cleaning for bedrooms is: {}\".format(train_df.shape))\n",
    "print(\"\\nThe test data size after data cleaning for bedrooms is: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b5e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.336661Z",
     "iopub.status.busy": "2024-10-28T22:51:50.336144Z",
     "iopub.status.idle": "2024-10-28T22:51:50.358084Z",
     "shell.execute_reply": "2024-10-28T22:51:50.356642Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.336605Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show datas with bathrooms is 0\n",
    "bathrooms_zero_train = train_df[train_df['bathrooms'] == 0]\n",
    "bathrooms_zero_test = test_df[test_df['bathrooms'] == 0]\n",
    "print(\"Bathrooms = 0:\")\n",
    "print(bathrooms_zero_train)\n",
    "print(bathrooms_zero_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c9aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.360656Z",
     "iopub.status.busy": "2024-10-28T22:51:50.359670Z",
     "iopub.status.idle": "2024-10-28T22:51:50.374885Z",
     "shell.execute_reply": "2024-10-28T22:51:50.373614Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.360611Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete rows with bathrooms == 0\n",
    "train_df = train_df[train_df['bathrooms'] != 0]\n",
    "test_df = test_df[test_df['bathrooms'] != 0]\n",
    "\n",
    "#Check the data size after data cleaning for bathrooms == 0\n",
    "print(\"\\nThe train data size after data cleaning for bathrooms is: {}\".format(train_df.shape))\n",
    "print(\"\\nThe test data size after data cleaning for bathrooms is: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cb71a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92084af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Special feature processing: zipcode and date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c4286",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**zipcode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d937c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.377037Z",
     "iopub.status.busy": "2024-10-28T22:51:50.376666Z",
     "iopub.status.idle": "2024-10-28T22:51:50.385516Z",
     "shell.execute_reply": "2024-10-28T22:51:50.384436Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.376997Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate the unique value\n",
    "unique_zipcodes = train_df['zipcode'].nunique()\n",
    "print(f\"Unique zipcodes: {unique_zipcodes}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fb2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.387732Z",
     "iopub.status.busy": "2024-10-28T22:51:50.387263Z",
     "iopub.status.idle": "2024-10-28T22:51:50.400785Z",
     "shell.execute_reply": "2024-10-28T22:51:50.399671Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.387681Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average house price/sqft_living for each zipcode in the training data\n",
    "train_df['price_per_sqft'] = train_df['price'] / train_df['sqft_living']\n",
    "zipcode_mean = train_df.groupby('zipcode')['price_per_sqft'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805dbc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.402705Z",
     "iopub.status.busy": "2024-10-28T22:51:50.402323Z",
     "iopub.status.idle": "2024-10-28T22:51:50.410107Z",
     "shell.execute_reply": "2024-10-28T22:51:50.409019Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.402664Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "zipcode_mean.columns = ['zipcode', 'zipcode_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c25ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.412002Z",
     "iopub.status.busy": "2024-10-28T22:51:50.411603Z",
     "iopub.status.idle": "2024-10-28T22:51:50.429606Z",
     "shell.execute_reply": "2024-10-28T22:51:50.428533Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.411955Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace the zipcode field in the training data with the encoded value\n",
    "train_df = train_df.merge(zipcode_mean, on='zipcode', how='left')\n",
    "train_df['zipcode'] = train_df['zipcode_encoded']\n",
    "train_df.drop(columns=['price_per_sqft', 'zipcode_encoded'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82615b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.431648Z",
     "iopub.status.busy": "2024-10-28T22:51:50.431170Z",
     "iopub.status.idle": "2024-10-28T22:51:50.441132Z",
     "shell.execute_reply": "2024-10-28T22:51:50.440173Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.431594Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply it to the test dataset\n",
    "# Merge encoded values into test data\n",
    "test_df = test_df.merge(zipcode_mean, on='zipcode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb430268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.443023Z",
     "iopub.status.busy": "2024-10-28T22:51:50.442614Z",
     "iopub.status.idle": "2024-10-28T22:51:50.462745Z",
     "shell.execute_reply": "2024-10-28T22:51:50.461530Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.442967Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the merge results\n",
    "print(\"Merged test data:\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2a71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.464338Z",
     "iopub.status.busy": "2024-10-28T22:51:50.463985Z",
     "iopub.status.idle": "2024-10-28T22:51:50.471003Z",
     "shell.execute_reply": "2024-10-28T22:51:50.469738Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.464300Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace the zipcode field in the test data with the encoded value\n",
    "# Make sure we check if zipcode_encoded exists\n",
    "if 'zipcode_encoded' in test_df.columns:\n",
    "    test_df['zipcode'] = test_df['zipcode_encoded']\n",
    "else:\n",
    "    print(\"No 'zipcode_encoded' column found in the test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d10fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.472682Z",
     "iopub.status.busy": "2024-10-28T22:51:50.472345Z",
     "iopub.status.idle": "2024-10-28T22:51:50.487949Z",
     "shell.execute_reply": "2024-10-28T22:51:50.486479Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.472645Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove columns that are no longer needed\n",
    "test_df.drop(columns=['zipcode_encoded'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8fc7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.490307Z",
     "iopub.status.busy": "2024-10-28T22:51:50.489874Z",
     "iopub.status.idle": "2024-10-28T22:51:50.521921Z",
     "shell.execute_reply": "2024-10-28T22:51:50.520711Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.490236Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the results \n",
    "print(\"Training data:\")\n",
    "print(train_df)\n",
    "print(\"\\nTest data:\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2d2f8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91e5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.523765Z",
     "iopub.status.busy": "2024-10-28T22:51:50.523397Z",
     "iopub.status.idle": "2024-10-28T22:51:50.534074Z",
     "shell.execute_reply": "2024-10-28T22:51:50.532749Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.523722Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use .loc to ensure operation on original DataFrame\n",
    "train_df.loc[:, 'is_train'] = 1  \n",
    "# Training set labeling\n",
    "test_df.loc[:, 'is_train'] = 0   \n",
    "# Test set labeling\n",
    "\n",
    "# Merge two datasets\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508812f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.536019Z",
     "iopub.status.busy": "2024-10-28T22:51:50.535645Z",
     "iopub.status.idle": "2024-10-28T22:51:50.565924Z",
     "shell.execute_reply": "2024-10-28T22:51:50.564640Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.535979Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb853ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.567843Z",
     "iopub.status.busy": "2024-10-28T22:51:50.567443Z",
     "iopub.status.idle": "2024-10-28T22:51:50.582436Z",
     "shell.execute_reply": "2024-10-28T22:51:50.581256Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.567800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime type\n",
    "all_data['date'] = pd.to_datetime(all_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bc77a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.584232Z",
     "iopub.status.busy": "2024-10-28T22:51:50.583836Z",
     "iopub.status.idle": "2024-10-28T22:51:50.597613Z",
     "shell.execute_reply": "2024-10-28T22:51:50.596491Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.584193Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the converted data type\n",
    "print(\"\\nThe converted data type:\")\n",
    "print(all_data.dtypes)\n",
    "\n",
    "# Verify that the conversion was successful\n",
    "print(\"\\nExample of converted date:\")\n",
    "print(all_data['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbdbed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.599503Z",
     "iopub.status.busy": "2024-10-28T22:51:50.599037Z",
     "iopub.status.idle": "2024-10-28T22:51:50.614344Z",
     "shell.execute_reply": "2024-10-28T22:51:50.613291Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.599460Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract year and month\n",
    "all_data['year_sold'] = all_data['date'].dt.year\n",
    "all_data['month_sold'] = all_data['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3452c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.616333Z",
     "iopub.status.busy": "2024-10-28T22:51:50.615959Z",
     "iopub.status.idle": "2024-10-28T22:51:50.625375Z",
     "shell.execute_reply": "2024-10-28T22:51:50.624175Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.616292Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the original date column\n",
    "all_data = all_data.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d525a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.627263Z",
     "iopub.status.busy": "2024-10-28T22:51:50.626873Z",
     "iopub.status.idle": "2024-10-28T22:51:50.643748Z",
     "shell.execute_reply": "2024-10-28T22:51:50.642559Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.627224Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset back to its original state\n",
    "train_df = all_data[all_data['is_train'] == 1].drop('is_train', axis=1)\n",
    "test_df = all_data[all_data['is_train'] == 0].drop(['is_train', 'price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b34594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.645742Z",
     "iopub.status.busy": "2024-10-28T22:51:50.645383Z",
     "iopub.status.idle": "2024-10-28T22:51:50.671991Z",
     "shell.execute_reply": "2024-10-28T22:51:50.670772Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.645703Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e949ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.673937Z",
     "iopub.status.busy": "2024-10-28T22:51:50.673570Z",
     "iopub.status.idle": "2024-10-28T22:51:50.700907Z",
     "shell.execute_reply": "2024-10-28T22:51:50.699798Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.673897Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32447aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.702920Z",
     "iopub.status.busy": "2024-10-28T22:51:50.702577Z",
     "iopub.status.idle": "2024-10-28T22:51:50.708790Z",
     "shell.execute_reply": "2024-10-28T22:51:50.707589Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.702883Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the processed shape\n",
    "print(f\"Training set: {train_df.shape}, Test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327a2d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Feature transformation (e.g., log transformation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a7066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.710585Z",
     "iopub.status.busy": "2024-10-28T22:51:50.710171Z",
     "iopub.status.idle": "2024-10-28T22:51:50.730719Z",
     "shell.execute_reply": "2024-10-28T22:51:50.729466Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.710532Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the shape and type of the price column\n",
    "print(\"Shape:\", train_df.price.shape)  \n",
    "# should be (n,)\n",
    "print(\"Type:\", type(train_df.price))  \n",
    "# should be a pandas Series\n",
    "\n",
    "# View the previous rows of data\n",
    "print(\"Sample Data:\\n\", train_df.price.head())\n",
    "\n",
    "# Confirm data type\n",
    "print(\"Data Types:\\n\", train_df.price.apply(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48093e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:50.732850Z",
     "iopub.status.busy": "2024-10-28T22:51:50.732348Z",
     "iopub.status.idle": "2024-10-28T22:51:51.186469Z",
     "shell.execute_reply": "2024-10-28T22:51:51.185173Z",
     "shell.execute_reply.started": "2024-10-28T22:51:50.732794Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check the distrubition of target variable price, in order to observe its skewness characteristics\n",
    "plt.hist(train_df.price, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e76d05",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The distribution of the target variable, price, shows significant skewness, indicating that it is not normally distributed. This lack of normality can negatively affect the performance of models that assume a normal distribution for optimal predictions.\n",
    "\n",
    "To address this, applying a logarithmic transformation to the price variable will help to reduce the skewness and approximate a more normal distribution.\n",
    "\n",
    "This transformation will be particularly beneficial when computing metrics in regression models, as it will ensure that errors and predictions are measured in a more balanced manner, leading to better results and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef547c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:51.188703Z",
     "iopub.status.busy": "2024-10-28T22:51:51.188179Z",
     "iopub.status.idle": "2024-10-28T22:51:51.200442Z",
     "shell.execute_reply": "2024-10-28T22:51:51.199266Z",
     "shell.execute_reply.started": "2024-10-28T22:51:51.188648Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert price to log price, use .loc to ensure the operation is on the original DataFrame\n",
    "train_df.loc[:, 'log_price'] = np.log(train_df['price'])\n",
    "\n",
    "# View the results of the first few rows\n",
    "print(train_df[['price', 'log_price']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39393be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:51.202135Z",
     "iopub.status.busy": "2024-10-28T22:51:51.201755Z",
     "iopub.status.idle": "2024-10-28T22:51:51.212729Z",
     "shell.execute_reply": "2024-10-28T22:51:51.211444Z",
     "shell.execute_reply.started": "2024-10-28T22:51:51.202094Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the shape of log_price\n",
    "print(train_df['log_price'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de578b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:51.214544Z",
     "iopub.status.busy": "2024-10-28T22:51:51.214143Z",
     "iopub.status.idle": "2024-10-28T22:51:51.633655Z",
     "shell.execute_reply": "2024-10-28T22:51:51.632321Z",
     "shell.execute_reply.started": "2024-10-28T22:51:51.214505Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(train_df.log_price, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Target Variable log_price')\n",
    "plt.xlabel('log_price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a52dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:51.635829Z",
     "iopub.status.busy": "2024-10-28T22:51:51.635332Z",
     "iopub.status.idle": "2024-10-28T22:51:51.650089Z",
     "shell.execute_reply": "2024-10-28T22:51:51.648686Z",
     "shell.execute_reply.started": "2024-10-28T22:51:51.635782Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The ID field is not used during processing, so delete it, but keep the ID for final output\n",
    "print(\"The train data size before dropping ID feature is: {}\".format(train_df.shape))\n",
    "print(\"The test data size before dropping ID feature is: {}\".format(test_df.shape))\n",
    "\n",
    "#Keep the ID column\n",
    "train_ID = train_df['id']\n",
    "test_ID = test_df['id']\n",
    "\n",
    "#Because the id is not necessary for prediction, delete it\n",
    "train_df.drop(\"id\", axis = 1, inplace = True)\n",
    "test_df.drop(\"id\", axis = 1, inplace = True)\n",
    "\n",
    "#View the data size after deleting the id\n",
    "print(\"\\nThe train data size after dropping id feature is: {}\".format(train_df.shape))\n",
    "print(\"\\nThe test data size after dropping id feature is: {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf12f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:51.652041Z",
     "iopub.status.busy": "2024-10-28T22:51:51.651611Z",
     "iopub.status.idle": "2024-10-28T22:51:53.518188Z",
     "shell.execute_reply": "2024-10-28T22:51:53.517136Z",
     "shell.execute_reply.started": "2024-10-28T22:51:51.651998Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume train is your dataset and already contains the 'log_price' column\n",
    "train_df_corr = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = train_df_corr.corr()\n",
    "\n",
    "# Sort: first based on correlation with 'SalePrice' (or 'log_price')\n",
    "corr_target_sorted = corr['log_price'].abs().sort_values(ascending=False).index\n",
    "\n",
    "# Rearrange the correlation matrix according to the sorting results (also remove the 'price' column and row)\n",
    "corr_sorted = corr.loc[corr_target_sorted, corr_target_sorted].drop('price', axis=1).drop('price', axis=0)\n",
    "\n",
    "# Visualize heatmap and adjust annotation font size\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_sorted, annot=True, cmap='coolwarm', square=True, annot_kws={\"size\": 8})\n",
    "plt.title('Correlation Matrix (sorted by correlation with log_price)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed28f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "grade, sqft_living, zipcode have the highest correlation with price:\n",
    "\n",
    "\n",
    "The other 3 variables with a correlation higher than 0.5 with price are: sqft_living15, sqft_above, bathrooms.\n",
    "\n",
    "sqft_living and sqft_above have a correlation of 0.88, meaning they move together strongly. It is multicollinearity. Why Multicollinearity is an Issue? When multicollinearity is present:\n",
    "\n",
    "Redundancy: Both variables are conveying essentially the same information. Including both doesn't add value and might lead to confusing results.\n",
    "Unstable Coefficients: The regression model may struggle to determine which variable (sqft_living or sqft_above) is more important, leading to unstable coefficient estimates. This means small changes in the data could cause large swings in the coefficients, making the model less reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb863b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:51:53.519822Z",
     "iopub.status.busy": "2024-10-28T22:51:53.519478Z",
     "iopub.status.idle": "2024-10-28T22:52:01.234220Z",
     "shell.execute_reply": "2024-10-28T22:52:01.233055Z",
     "shell.execute_reply.started": "2024-10-28T22:51:53.519782Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "sns.set()\n",
    "\n",
    "# Define columns for the scatterplot\n",
    "cols = ['price', 'sqft_living', 'grade', 'sqft_above', 'sqft_living15', 'zipcode', 'bathrooms', \n",
    "        'view', 'bedrooms', 'sqft_basement', 'lat', 'floors', 'waterfront', 'yr_renovated', \n",
    "        'sqft_lot', 'sqft_lot15', 'yr_built', 'condition', 'long', 'month_sold', 'year_sold']\n",
    "\n",
    "# Create scatterplots only between 'price' and the other variables\n",
    "sns.pairplot(train_df, x_vars=cols[1:], y_vars='price', height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05dd66d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:01.236341Z",
     "iopub.status.busy": "2024-10-28T22:52:01.235880Z",
     "iopub.status.idle": "2024-10-28T22:52:08.900462Z",
     "shell.execute_reply": "2024-10-28T22:52:08.899298Z",
     "shell.execute_reply.started": "2024-10-28T22:52:01.236272Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "sns.set()\n",
    "\n",
    "# Define columns for the scatterplot\n",
    "cols = ['log_price', 'sqft_living', 'grade', 'sqft_above', 'sqft_living15', 'zipcode', 'bathrooms', \n",
    "        'view', 'bedrooms', 'sqft_basement', 'lat', 'floors', 'waterfront', 'yr_renovated', \n",
    "        'sqft_lot', 'sqft_lot15', 'yr_built', 'condition', 'long', 'month_sold', 'year_sold']\n",
    "\n",
    "# Create scatterplots only between 'price' and the other variables\n",
    "sns.pairplot(train_df, x_vars=cols[1:], y_vars='log_price', height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297dae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:08.902536Z",
     "iopub.status.busy": "2024-10-28T22:52:08.902070Z",
     "iopub.status.idle": "2024-10-28T22:52:27.980135Z",
     "shell.execute_reply": "2024-10-28T22:52:27.978769Z",
     "shell.execute_reply.started": "2024-10-28T22:52:08.902465Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = ['price', 'grade', 'zipcode', 'sqft_living', 'sqft_living15', 'sqft_above', 'bathrooms']\n",
    "sns.pairplot(train_df[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062576f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "This pair plot helps us explore the pairwise relationships between these variables, allowing us to visually inspect potential correlations, outliers, or patterns that could be useful for our house price prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e322a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection and Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba18944",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M1:use all features for linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889b21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:27.982323Z",
     "iopub.status.busy": "2024-10-28T22:52:27.981861Z",
     "iopub.status.idle": "2024-10-28T22:52:28.396549Z",
     "shell.execute_reply": "2024-10-28T22:52:28.395553Z",
     "shell.execute_reply.started": "2024-10-28T22:52:27.982255Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume train_df is the training dataset\n",
    "X = train_df.drop(columns=['log_price','price'])\n",
    "y = train_df['log_price']\n",
    "\n",
    "# Creating a Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define RMSE scoring function\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Cross-validation using KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "# 5-fold Cross-validation\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=kf)\n",
    "\n",
    "# Output cross-validation RMSE\n",
    "print(\"Cross-validated RMSE scores:\", scores)\n",
    "print(\"Mean RMSE:\", np.mean(scores))\n",
    "\n",
    "# Fitting the final model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Use statsmodels to refit the model and output the OLS regression results table\n",
    "X_with_const = sm.add_constant(X)  \n",
    "# Add a constant term (intercept term)\n",
    "ols_model = sm.OLS(y, X_with_const).fit()  \n",
    "# Fit the OLS model\n",
    "\n",
    "# Output OLS regression results\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d13815",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M2: Based on VIF, eliminate multicollinearity between some independent variables and use some features for linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a8c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:28.401942Z",
     "iopub.status.busy": "2024-10-28T22:52:28.401171Z",
     "iopub.status.idle": "2024-10-28T22:52:29.280259Z",
     "shell.execute_reply": "2024-10-28T22:52:29.278817Z",
     "shell.execute_reply.started": "2024-10-28T22:52:28.401892Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume train_df is your DataFrame, containing all features\n",
    "# Selecting Numeric Features\n",
    "train_df_corr = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = train_df_corr.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(train_df_corr.values, i) for i in range(train_df_corr.shape[1])]\n",
    "\n",
    "# Output VIF data\n",
    "print(vif_data)\n",
    "\n",
    "# Filter features whose VIF values exceed the threshold\n",
    "threshold = 10  \n",
    "high_vif_features = vif_data[vif_data[\"VIF\"] > threshold]\n",
    "\n",
    "# Display high VIF features\n",
    "print(\"Features with VIF greater than\", threshold)\n",
    "print(high_vif_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f26e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:29.283196Z",
     "iopub.status.busy": "2024-10-28T22:52:29.282337Z",
     "iopub.status.idle": "2024-10-28T22:52:29.294036Z",
     "shell.execute_reply": "2024-10-28T22:52:29.292599Z",
     "shell.execute_reply.started": "2024-10-28T22:52:29.283122Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750a0af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:29.297544Z",
     "iopub.status.busy": "2024-10-28T22:52:29.296432Z",
     "iopub.status.idle": "2024-10-28T22:52:29.751801Z",
     "shell.execute_reply": "2024-10-28T22:52:29.750370Z",
     "shell.execute_reply.started": "2024-10-28T22:52:29.297452Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume train_df is your training dataset\n",
    "X = train_df.drop(columns=['log_price', 'price','sqft_above', 'sqft_basement', 'sqft_living15', 'bathrooms'])\n",
    "y = train_df['log_price']\n",
    "\n",
    "# Creating a Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define RMSE scoring function\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Cross-validation using KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "# 5-fold Cross-validation\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=kf)\n",
    "\n",
    "# RMSE\n",
    "print(\"Cross-validated RMSE scores:\", scores)\n",
    "print(\"Mean RMSE:\", np.mean(scores))\n",
    "\n",
    "# Fitting the final model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Use statsmodels to refit the model and output the OLS regression results table\n",
    "# Here you need to add a constant term (intercept term) to X\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Fitting an OLS model using statsmodels\n",
    "ols_model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "# Output OLS regression results\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5801c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M3: Remove insignificant independent variables after dealing with multicollinearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c3b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:29.755451Z",
     "iopub.status.busy": "2024-10-28T22:52:29.754343Z",
     "iopub.status.idle": "2024-10-28T22:52:30.110064Z",
     "shell.execute_reply": "2024-10-28T22:52:30.108575Z",
     "shell.execute_reply.started": "2024-10-28T22:52:29.755375Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assume train_df is the training dataset\n",
    "X = train_df.drop(columns=['log_price', 'price','sqft_above', 'sqft_basement', 'sqft_living15', 'bathrooms','floors','sqft_lot15'])\n",
    "y = train_df['log_price']\n",
    "\n",
    "# Creating a Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define RMSE scoring function\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Cross-validation using KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "# 5-fold Cross-validatio\n",
    "\n",
    "# Cross-validatio\n",
    "scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=kf)\n",
    "\n",
    "# print RMSE\n",
    "print(\"Cross-validated RMSE scores:\", scores)\n",
    "print(\"Mean RMSE:\", np.mean(scores))\n",
    "\n",
    "# Fitting the final model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Use statsmodels to refit the model and output the OLS regression results table\n",
    "# Here you need to add a constant term (intercept term) to X\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Fitting an OLS model using statsmodels\n",
    "ols_model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "# Output OLS regression results\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631f049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:30.121066Z",
     "iopub.status.busy": "2024-10-28T22:52:30.117220Z",
     "iopub.status.idle": "2024-10-28T22:52:30.146240Z",
     "shell.execute_reply": "2024-10-28T22:52:30.144604Z",
     "shell.execute_reply.started": "2024-10-28T22:52:30.120982Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using the model to make predictions\n",
    "y_pred_log_price = model.predict(X)\n",
    "\n",
    "# Convert predicted log_price to price\n",
    "y_pred_price = np.exp(y_pred_log_price)\n",
    "\n",
    "# Convert actual log_price to price\n",
    "y_actual_price = np.exp(y)\n",
    "\n",
    "# Calculate RMSE on the price scale\n",
    "rmse_price = mean_squared_error(y_actual_price, y_pred_price, squared=False)  \n",
    "# squared=False return RMSE\n",
    "print(f\"Price Scale RMSE: {rmse_price:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46464",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M4 & M5: Try Lasso、Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b1bd5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:52:30.157393Z",
     "iopub.status.busy": "2024-10-28T22:52:30.153614Z",
     "iopub.status.idle": "2024-10-28T22:53:08.517558Z",
     "shell.execute_reply": "2024-10-28T22:53:08.516253Z",
     "shell.execute_reply.started": "2024-10-28T22:52:30.157312Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df.drop(columns=['log_price', 'price'])\n",
    "y_train = train_df['log_price']\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "# Identify categorical features for encoding\n",
    "categorical_features = []\n",
    "numeric_features = X_train.columns.difference(categorical_features)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Lasso': LassoCV(alphas=np.logspace(-3, 2, 100), cv=5, random_state=42),\n",
    "    'Ridge': RidgeCV(alphas=np.logspace(-3, 2, 100), cv=5),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    # Cross-validation\n",
    "    scores = cross_validate(pipeline, X_train, y_train, cv=5,\n",
    "                            scoring=('neg_root_mean_squared_error', 'neg_mean_absolute_error', 'r2'),\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"  RMSE: {-np.mean(scores['test_neg_root_mean_squared_error'])}\")\n",
    "    print(f\"  MAE: {-np.mean(scores['test_neg_mean_absolute_error'])}\")\n",
    "    print(f\"  R²: {np.mean(scores['test_r2'])}\")\n",
    "    # Fit the model on the entire training data to extract feature importance\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    if name in ['Lasso', 'Ridge']:\n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "        # Get coefficients from the model\n",
    "        coefficients = pipeline.named_steps['model'].coef_\n",
    "        \n",
    "        # For Lasso, filter out zero coefficients\n",
    "        if name == 'Lasso':\n",
    "            selected_features = feature_names[coefficients != 0]\n",
    "            selected_coefficients = coefficients[coefficients != 0]\n",
    "        else:\n",
    "            selected_features = feature_names\n",
    "            selected_coefficients = coefficients\n",
    "        \n",
    "        # Print all features and their coefficients for Lasso/Ridge\n",
    "        for feature, coef in zip(selected_features, selected_coefficients):\n",
    "            print(f\"Feature: {feature}, Coefficient: {coef}\")\n",
    "        \n",
    "        # Sort features by absolute coefficient value\n",
    "        sorted_indices = np.argsort(np.abs(selected_coefficients))[::-1]\n",
    "        sorted_features = selected_features[sorted_indices]\n",
    "        sorted_coefficients = selected_coefficients[sorted_indices]\n",
    "\n",
    "        # Plotting sorted feature importances for Lasso/Ridge\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(sorted_features[:10], sorted_coefficients[:10])  # Plot top 10 features by absolute value of coefficient\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.title(f'Top Features by Coefficient - {name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c1476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:08.520321Z",
     "iopub.status.busy": "2024-10-28T22:53:08.519337Z",
     "iopub.status.idle": "2024-10-28T22:53:08.526465Z",
     "shell.execute_reply": "2024-10-28T22:53:08.525342Z",
     "shell.execute_reply.started": "2024-10-28T22:53:08.520243Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Lasso  RMSE（Original）: {np.exp(0.18660178373477715) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964305b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:08.528750Z",
     "iopub.status.busy": "2024-10-28T22:53:08.528263Z",
     "iopub.status.idle": "2024-10-28T22:53:08.540611Z",
     "shell.execute_reply": "2024-10-28T22:53:08.539362Z",
     "shell.execute_reply.started": "2024-10-28T22:53:08.528695Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Ridge  RMSE（Original）: {np.exp(0.1865838851032337) - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac55abb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M5: Random Forests**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ebd32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Steps to Determine Feature Contributions\n",
    "\n",
    "1. Train the Random Forest Model: Fit a Random Forest model to your training data.\n",
    "2. Extract Feature Importances: Use the featureimportances attribute to get the importance score for each feature.\n",
    "3. Sort and Display Top Features: Sort these scores to find the most important features and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f24758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:08.542475Z",
     "iopub.status.busy": "2024-10-28T22:53:08.542068Z",
     "iopub.status.idle": "2024-10-28T22:53:27.411438Z",
     "shell.execute_reply": "2024-10-28T22:53:27.410255Z",
     "shell.execute_reply.started": "2024-10-28T22:53:08.542433Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest feature importances\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor), ('model', rf_model)])\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model: Random Forest\")\n",
    "print(f\"  RMSE: {-np.mean(scores['test_neg_root_mean_squared_error'])}\")\n",
    "print(f\"  R²: {np.mean(scores['test_r2'])}\")\n",
    "    \n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "rf_selected_features = feature_names[np.argsort(rf_feature_importance)[-10:]]  # Top 10 important features\n",
    "print(\"Top Random Forest features:\", rf_selected_features)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_feature_importance\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 10 features\n",
    "print(\"Top 10 Features by Importance:\")\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "# Optionally, plot feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'].head(10), feature_importance_df['Importance'].head(10))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importances in Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef9f0a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**M6: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab46f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:27.413070Z",
     "iopub.status.busy": "2024-10-28T22:53:27.412722Z",
     "iopub.status.idle": "2024-10-28T22:53:27.421681Z",
     "shell.execute_reply": "2024-10-28T22:53:27.420447Z",
     "shell.execute_reply.started": "2024-10-28T22:53:27.413031Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_xgb = train_df.drop(columns=[\"log_price\",\"price\"])  \n",
    "# All features\n",
    "y_xgb = train_df[\"log_price\"]  \n",
    "# Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9706ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:27.423623Z",
     "iopub.status.busy": "2024-10-28T22:53:27.423116Z",
     "iopub.status.idle": "2024-10-28T22:53:27.439394Z",
     "shell.execute_reply": "2024-10-28T22:53:27.438225Z",
     "shell.execute_reply.started": "2024-10-28T22:53:27.423577Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split the dataset into training and testing sets\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb, y_xgb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f3ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:27.441209Z",
     "iopub.status.busy": "2024-10-28T22:53:27.440785Z",
     "iopub.status.idle": "2024-10-28T22:53:27.446966Z",
     "shell.execute_reply": "2024-10-28T22:53:27.445928Z",
     "shell.execute_reply.started": "2024-10-28T22:53:27.441147Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create XGBoost model\n",
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050155e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:27.448949Z",
     "iopub.status.busy": "2024-10-28T22:53:27.448577Z",
     "iopub.status.idle": "2024-10-28T22:53:27.459939Z",
     "shell.execute_reply": "2024-10-28T22:53:27.458732Z",
     "shell.execute_reply.started": "2024-10-28T22:53:27.448908Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6],  # Reduce the depth of the tree\n",
    "    'learning_rate': [0.01, 0.05],  # Lower the learning rate\n",
    "    'n_estimators': [100, 200, 300],  # Increase n_estimators\n",
    "    'subsample': [0.7, 0.8],  # Using Subsets\n",
    "    'reg_alpha': [0, 0.1, 0.5],  # L1 Regularization\n",
    "    'reg_lambda': [1.0, 1.5]  # L2 Regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320d41a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:53:27.461930Z",
     "iopub.status.busy": "2024-10-28T22:53:27.461448Z",
     "iopub.status.idle": "2024-10-28T22:54:00.135075Z",
     "shell.execute_reply": "2024-10-28T22:54:00.133740Z",
     "shell.execute_reply.started": "2024-10-28T22:53:27.461874Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using random search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_log_error',\n",
    "    cv=3,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train_xgb, y_train_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397932a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:00.148955Z",
     "iopub.status.busy": "2024-10-28T22:54:00.148529Z",
     "iopub.status.idle": "2024-10-28T22:54:00.154018Z",
     "shell.execute_reply": "2024-10-28T22:54:00.152747Z",
     "shell.execute_reply.started": "2024-10-28T22:54:00.148912Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038660be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:00.156199Z",
     "iopub.status.busy": "2024-10-28T22:54:00.155743Z",
     "iopub.status.idle": "2024-10-28T22:54:01.652362Z",
     "shell.execute_reply": "2024-10-28T22:54:01.651324Z",
     "shell.execute_reply.started": "2024-10-28T22:54:00.156141Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "evals = [(X_train_xgb, y_train_xgb), (X_test_xgb, y_test_xgb)]  \n",
    "# Monitoring training and test sets\n",
    "best_model.fit(X_train_xgb, y_train_xgb, eval_set=evals, early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107d982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:01.655979Z",
     "iopub.status.busy": "2024-10-28T22:54:01.655613Z",
     "iopub.status.idle": "2024-10-28T22:54:01.679857Z",
     "shell.execute_reply": "2024-10-28T22:54:01.678888Z",
     "shell.execute_reply.started": "2024-10-28T22:54:01.655942Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the best model to make predictions on the test set\n",
    "y_pred_xgb = best_model.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00d2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:01.682375Z",
     "iopub.status.busy": "2024-10-28T22:54:01.681482Z",
     "iopub.status.idle": "2024-10-28T22:54:01.696092Z",
     "shell.execute_reply": "2024-10-28T22:54:01.695077Z",
     "shell.execute_reply.started": "2024-10-28T22:54:01.682317Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = mean_squared_error(y_test_xgb, y_pred_xgb, squared=False)  \n",
    "# squared=False return RMSE\n",
    "print(f\"Score: {rmse:.5f} RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e101e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:01.699253Z",
     "iopub.status.busy": "2024-10-28T22:54:01.698752Z",
     "iopub.status.idle": "2024-10-28T22:54:01.707714Z",
     "shell.execute_reply": "2024-10-28T22:54:01.706376Z",
     "shell.execute_reply.started": "2024-10-28T22:54:01.699194Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate R^2\n",
    "r_squared = r2_score(y_test_xgb, y_pred_xgb)\n",
    "print(f\"R^2 Score: {r_squared:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4051c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:01.709721Z",
     "iopub.status.busy": "2024-10-28T22:54:01.709260Z",
     "iopub.status.idle": "2024-10-28T22:54:01.718740Z",
     "shell.execute_reply": "2024-10-28T22:54:01.717403Z",
     "shell.execute_reply.started": "2024-10-28T22:54:01.709672Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d12590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:01.720599Z",
     "iopub.status.busy": "2024-10-28T22:54:01.720181Z",
     "iopub.status.idle": "2024-10-28T22:54:02.342691Z",
     "shell.execute_reply": "2024-10-28T22:54:02.341622Z",
     "shell.execute_reply.started": "2024-10-28T22:54:01.720527Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Draw a feature importance graph without displaying the default values\n",
    "ax = xgb.plot_importance(best_model, importance_type='gain', show_values=False)\n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "\n",
    "# Add text labels to the bar chart, formatted to two decimal places\n",
    "for p in ax.patches:\n",
    "    # Set the label text format to two decimal places\n",
    "    label = f\"{p.get_width():.2f}\"\n",
    "    # Set the label position, slightly offset to the right to avoid overlapping\n",
    "    ax.annotate(label, \n",
    "                (p.get_width() + 0.01, p.get_y() + p.get_height() / 2), \n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Get feature importance and sort by importance\n",
    "feature_importance = best_model.get_booster().get_score(importance_type='gain')\n",
    "sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Feature importance (sorted by gain):\")\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90233ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:02.344765Z",
     "iopub.status.busy": "2024-10-28T22:54:02.344332Z",
     "iopub.status.idle": "2024-10-28T22:54:02.353792Z",
     "shell.execute_reply": "2024-10-28T22:54:02.352498Z",
     "shell.execute_reply.started": "2024-10-28T22:54:02.344695Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert predicted log_price to price\n",
    "y_pred_price = np.exp(y_pred_xgb)\n",
    "\n",
    "# Convert actual log_price to price\n",
    "y_test_price = np.exp(y_test_xgb)\n",
    "\n",
    "# Calculate RMSE on the price scale\n",
    "rmse_price = mean_squared_error(y_test_price, y_pred_price, squared=False)  \n",
    "# squared=False return RMSE\n",
    "print(f\"Price Scale RMSE: {rmse_price:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01ecb0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Best Model and Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e051a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:02.355893Z",
     "iopub.status.busy": "2024-10-28T22:54:02.355117Z",
     "iopub.status.idle": "2024-10-28T22:54:02.370451Z",
     "shell.execute_reply": "2024-10-28T22:54:02.369363Z",
     "shell.execute_reply.started": "2024-10-28T22:54:02.355826Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with data\n",
    "data = {\n",
    "    'Model': [\n",
    "        'Simple Linear Regression',\n",
    "        'Linear Regression with Multicollinearity Handling',\n",
    "        'Linear Regression with Multicollinearity Handling and Removal of Insignificant Variables',\n",
    "        'Lasso',\n",
    "        'Ridge',\n",
    "        'Random Forest',\n",
    "        'XGBoost'\n",
    "    ],\n",
    "    'RMSE': [0.1863, 0.1920, 0.1919, 0.1865, 0.1865, 0.1865, 0.1583],\n",
    "    'R^2': [0.8740, 0.8670, 0.8670, 0.8737, 0.8738, 0.8738, 0.9103]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set display options to format float numbers\n",
    "pd.options.display.float_format = '{:.4f}'.format  # Use 4 decimal places\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4fdcda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We have chosen to use the **XGBoost model** for predicting house sale prices due to several important reasons:\n",
    "1. Lowest RMSE: XGBoost has the lowest RMSE (0.1583), indicating the smallest prediction error among all models.\n",
    "2. Highest R²: XGBoost has the highest R² value (0.9103), suggesting that it explains a significant portion of the variance in house sale prices.\n",
    "3. Robustness: As a tree-based ensemble method, XGBoost effectively captures complex relationships in the data, making it less prone to overfitting compared to simpler models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e21a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Results, Findings, and Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31153e1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Test Data Price Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee341c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T22:54:02.372228Z",
     "iopub.status.busy": "2024-10-28T22:54:02.371855Z",
     "iopub.status.idle": "2024-10-28T22:54:02.430449Z",
     "shell.execute_reply": "2024-10-28T22:54:02.429343Z",
     "shell.execute_reply.started": "2024-10-28T22:54:02.372186Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, we select XGBoost and print the prediction results to another file\n",
    "\n",
    "# 1. Preparing test data\n",
    "X_test_df = test_df.copy()  \n",
    "# Use a copy of test_df, keeping all features\n",
    "\n",
    "# 2. Use the best model to make predictions\n",
    "y_pred_log_price = best_model.predict(X_test_df)  \n",
    "# predict log_price\n",
    "\n",
    "# 3. change log_price to price\n",
    "y_pred_price = np.exp(y_pred_log_price)  \n",
    "# Convert log_price to price using exponential function\n",
    "\n",
    "# 4. Create a new DataFrame to save the prediction results\n",
    "results_df = pd.DataFrame({\n",
    "    'id': test_ID,  \n",
    "    # Extract id from reserved test_ID\n",
    "    'predicted_price': y_pred_price  \n",
    "    # Adding predicted price\n",
    "})\n",
    "\n",
    "# 5. Save the prediction results to a CSV file, making sure the id is in the first column\n",
    "results_df.to_csv('predicted_prices.csv', index=False)  \n",
    "# Do not keep index\n",
    "\n",
    "# 6. Print prediction results\n",
    "print(results_df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb817a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Important Features for Determining the House Price\n",
    "\n",
    "1. Grade: [level of construction and design] \n",
    "It is  reasonable that a  house in  good construction and design quality will  be more attractive to consumers, resulting in a higher price for sale.\n",
    "\n",
    "2. Zipcode: [the average price per square meter in the area]\n",
    "Represent the geographic location, areas close to city centers, lakes, or transportation hubs typically have higher property values.\n",
    "\n",
    "3. sqft_living: [Square footage of the apartments interior living space] \n",
    "The  larger the house, the greater amount of money customers need to pay."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5936141,
     "sourceId": 9706016,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5936142,
     "sourceId": 9706017,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5943239,
     "sourceId": 9715155,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5943242,
     "sourceId": 9715158,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5967974,
     "sourceId": 9748255,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.803403,
   "end_time": "2024-10-28T22:58:10.203869",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-28T22:58:00.400466",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
